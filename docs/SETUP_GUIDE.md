# Olist Database Setup Guide

## ğŸ“‹ Prerequisites

### 1. Install PostgreSQL

**Windows:**
- Download from: https://www.postgresql.org/download/windows/
- Or use Chocolatey: `choco install postgresql`

**Verify installation:**
```powershell
psql --version
```

### 2. Install Python Dependencies

```powershell
# Create virtual environment (recommended)
python -m venv venv
.\venv\Scripts\Activate.ps1

# Install dependencies
pip install -r requirements.txt
```

### 3. Setup Kaggle API

**Option A: Using .env file (Recommended)**
1. Get your API credentials from: https://www.kaggle.com/settings
2. Copy `.env.example` to `.env`
3. Add your credentials:
   ```
   KAGGLE_USERNAME=your_username
   KAGGLE_KEY=your_api_key
   ```

**Option B: Using kaggle.json**
1. Download `kaggle.json` from: https://www.kaggle.com/settings
2. Place it in: `C:\Users\<YourUsername>\.kaggle\kaggle.json`

### 4. Configure Database Connection

Edit `.env` file with your PostgreSQL credentials:
```
DB_HOST=localhost
DB_PORT=5432
DB_NAME=olist_ecommerce
DB_USER=postgres
DB_PASSWORD=your_password
```

## ğŸš€ Step-by-Step Setup

### Step 1: Download the Dataset

```powershell
python scripts/download_dataset.py
```

**Expected output:**
- 9 CSV files downloaded to `data/` folder
- Total size: ~126 MB

**Files downloaded:**
- `olist_customers_dataset.csv` (~9 MB)
- `olist_geolocation_dataset.csv` (largest)
- `olist_order_items_dataset.csv`
- `olist_order_payments_dataset.csv`
- `olist_order_reviews_dataset.csv`
- `olist_orders_dataset.csv`
- `olist_products_dataset.csv`
- `olist_sellers_dataset.csv`
- `product_category_name_translation.csv`

### Step 2: Explore the Data (Optional)

```powershell
python scripts/explore_data.py
```

This will show you:
- Column names and data types
- Sample data from each file
- Basic statistics
- Null value percentages

### Step 3: Create Database Schema

```powershell
python scripts/setup_database.py
```

**What this does:**
- Creates database `olist_ecommerce` (if it doesn't exist)
- Creates 9 tables with proper relationships
- Adds indexes for performance
- Creates a summary view for easy analysis

**Tables created:**
- `customers`
- `sellers`
- `products`
- `product_category_translation`
- `orders`
- `order_items`
- `order_payments`
- `order_reviews`
- `geolocation`

### Step 4: Load Data into PostgreSQL

```powershell
python scripts/load_data.py
```

**This process:**
- Reads all CSV files
- Cleans and validates data
- Inserts data in proper order (respecting foreign keys)
- Shows progress bars
- Handles duplicates in geolocation data

**Expected time:** 2-5 minutes depending on your system

## âœ… Verify Installation

### Connect to PostgreSQL

```powershell
psql -U postgres -d olist_ecommerce
```

### Run test queries:

```sql
-- Check table counts
SELECT 'orders' as table_name, COUNT(*) FROM orders
UNION ALL
SELECT 'customers', COUNT(*) FROM customers
UNION ALL
SELECT 'products', COUNT(*) FROM products;

-- Sample order summary
SELECT * FROM order_summary LIMIT 5;

-- Top 5 cities by orders
SELECT customer_city, COUNT(*) as orders
FROM customers c
JOIN orders o ON c.customer_id = o.customer_id
GROUP BY customer_city
ORDER BY orders DESC
LIMIT 5;
```

## ğŸ“Š Database Schema Overview

```
customers
â”œâ”€â”€ customer_id (PK)
â”œâ”€â”€ customer_unique_id
â”œâ”€â”€ customer_zip_code_prefix
â”œâ”€â”€ customer_city
â””â”€â”€ customer_state

orders
â”œâ”€â”€ order_id (PK)
â”œâ”€â”€ customer_id (FK â†’ customers)
â”œâ”€â”€ order_status
â”œâ”€â”€ order_purchase_timestamp
â”œâ”€â”€ order_approved_at
â”œâ”€â”€ order_delivered_carrier_date
â”œâ”€â”€ order_delivered_customer_date
â””â”€â”€ order_estimated_delivery_date

order_items
â”œâ”€â”€ order_id (FK â†’ orders)
â”œâ”€â”€ order_item_id
â”œâ”€â”€ product_id (FK â†’ products)
â”œâ”€â”€ seller_id (FK â†’ sellers)
â”œâ”€â”€ shipping_limit_date
â”œâ”€â”€ price
â””â”€â”€ freight_value

products
â”œâ”€â”€ product_id (PK)
â”œâ”€â”€ product_category_name
â”œâ”€â”€ product_name_length
â”œâ”€â”€ product_description_length
â”œâ”€â”€ product_photos_qty
â”œâ”€â”€ product_weight_g
â”œâ”€â”€ product_length_cm
â”œâ”€â”€ product_height_cm
â””â”€â”€ product_width_cm

sellers
â”œâ”€â”€ seller_id (PK)
â”œâ”€â”€ seller_zip_code_prefix
â”œâ”€â”€ seller_city
â””â”€â”€ seller_state

order_reviews
â”œâ”€â”€ review_id (PK)
â”œâ”€â”€ order_id (FK â†’ orders)
â”œâ”€â”€ review_score
â”œâ”€â”€ review_comment_title
â”œâ”€â”€ review_comment_message
â”œâ”€â”€ review_creation_date
â””â”€â”€ review_answer_timestamp

order_payments
â”œâ”€â”€ order_id (FK â†’ orders)
â”œâ”€â”€ payment_sequential
â”œâ”€â”€ payment_type
â”œâ”€â”€ payment_installments
â””â”€â”€ payment_value

geolocation
â”œâ”€â”€ geolocation_zip_code_prefix
â”œâ”€â”€ geolocation_lat
â”œâ”€â”€ geolocation_lng
â”œâ”€â”€ geolocation_city
â””â”€â”€ geolocation_state
```

## ğŸ” Sample Queries

See `scripts/sample_queries.sql` for a comprehensive collection of useful queries including:
- Sales analysis
- Customer behavior
- Product performance
- Delivery metrics
- Review analysis
- Geographic insights

## ğŸ› Troubleshooting

### "Kaggle API credentials not found"
- Make sure you've added credentials to `.env` or placed `kaggle.json` in the right location
- Check file permissions

### "Password authentication failed for user postgres"
- Verify your PostgreSQL password in `.env`
- Try resetting your PostgreSQL password:
  ```sql
  ALTER USER postgres PASSWORD 'new_password';
  ```

### "Database already exists"
- The script will use the existing database
- To start fresh: `DROP DATABASE olist_ecommerce;` in psql

### "CSV files not found"
- Make sure Step 1 (download) completed successfully
- Check that files exist in `data/` folder

### Import errors (psycopg2, pandas, etc.)
- Make sure you activated the virtual environment
- Run: `pip install -r requirements.txt`

## ğŸ“š Next Steps

Now that your database is set up, you can:

1. **Explore the data** using the sample queries
2. **Build the agent system** for autonomous analysis
3. **Create visualizations** of key metrics
4. **Develop the multi-agent architecture** with LangGraph

Check out the main README.md for the full project roadmap!
